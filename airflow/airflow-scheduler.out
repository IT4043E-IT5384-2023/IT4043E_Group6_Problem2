[[34m2023-12-23T16:37:27.749+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2023-12-23T16:37:27.750+0000[0m] {[34mexecutor_loader.py:[0m115} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2023-12-23T16:37:32.791+0000[0m] {[34mscheduler_job_runner.py:[0m808} INFO[0m - Starting the scheduler[0m
[[34m2023-12-23T16:37:32.791+0000[0m] {[34mscheduler_job_runner.py:[0m815} INFO[0m - Processing each file at most -1 times[0m
[[34m2023-12-23T16:37:32.797+0000[0m] {[34mmanager.py:[0m169} INFO[0m - Launched DagFileProcessorManager with pid: 37022[0m
[[34m2023-12-23T16:37:32.798+0000[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2023-12-23T16:37:32.800+0000[0m] {[34msettings.py:[0m61} INFO[0m - Configured default timezone Timezone('UTC')[0m
[[34m2023-12-23T16:37:32.891+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: process_questn_data.run manual__2023-12-23T14:38:27.276741+00:00 [scheduled]>[0m
[[34m2023-12-23T16:37:32.892+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG process_questn_data has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:37:32.892+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: process_questn_data.run manual__2023-12-23T14:38:27.276741+00:00 [scheduled]>[0m
[[34m2023-12-23T16:37:32.895+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='process_questn_data', task_id='run', run_id='manual__2023-12-23T14:38:27.276741+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:37:32.896+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'process_questn_data', 'run', 'manual__2023-12-23T14:38:27.276741+00:00', '--local', '--subdir', 'DAGS_FOLDER/questn_data.py'][0m
[[34m2023-12-23T16:37:32.898+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'process_questn_data', 'run', 'manual__2023-12-23T14:38:27.276741+00:00', '--local', '--subdir', 'DAGS_FOLDER/questn_data.py'][0m
[[34m2023-12-23T16:37:33.932+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/questn_data.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
[[34m2023-12-23T16:37:36.239+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: process_questn_data.run manual__2023-12-23T14:38:27.276741+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:37:37.305+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='process_questn_data', task_id='run', run_id='manual__2023-12-23T14:38:27.276741+00:00', try_number=2, map_index=-1)[0m
[[34m2023-12-23T16:37:37.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=process_questn_data, task_id=run, run_id=manual__2023-12-23T14:38:27.276741+00:00, map_index=-1, run_start_date=2023-12-23 16:37:36.306793+00:00, run_end_date=2023-12-23 16:37:36.445624+00:00, run_duration=0.138831, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:37:32.893997+00:00, queued_by_job_id=9, pid=37086[0m
[[34m2023-12-23T16:37:37.338+0000[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun process_questn_data @ 2023-12-23 14:38:27.276741+00:00: manual__2023-12-23T14:38:27.276741+00:00, state:running, queued_at: 2023-12-23 14:38:27.283621+00:00. externally triggered: True> failed[0m
[[34m2023-12-23T16:37:37.339+0000[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=process_questn_data, execution_date=2023-12-23 14:38:27.276741+00:00, run_id=manual__2023-12-23T14:38:27.276741+00:00, run_start_date=2023-12-23 14:38:27.858420+00:00, run_end_date=2023-12-23 16:37:37.339155+00:00, run_duration=7149.480735, state=failed, external_trigger=True, run_type=manual, data_interval_start=2023-12-22 14:38:27.276741+00:00, data_interval_end=2023-12-23 14:38:27.276741+00:00, dag_hash=0e5c07b3b3e94dde5d9830ecd0c42bcd[0m
[[34m2023-12-23T16:41:00.087+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for db_snapshot to 2023-12-22T00:00:00+00:00, run_after=2023-12-23T00:00:00+00:00[0m
[[34m2023-12-23T16:41:00.092+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for cleanup to 2023-12-22T00:00:00+00:00, run_after=2023-12-23T00:00:00+00:00[0m
[[34m2023-12-23T16:41:00.114+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:41:00.114+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG db_snapshot has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:41:00.115+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG cleanup has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:41:00.115+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>
	<TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:41:00.116+0000[0m] {[34mtaskinstance.py:[0m2261} WARNING[0m - cannot record scheduled_duration for task run because previous state change time has not been saved[0m
[[34m2023-12-23T16:41:00.116+0000[0m] {[34mtaskinstance.py:[0m2261} WARNING[0m - cannot record scheduled_duration for task run because previous state change time has not been saved[0m
[[34m2023-12-23T16:41:00.117+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:41:00.117+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:41:00.117+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:41:00.117+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:41:00.118+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:41:01.073+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/db_snapshot.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
Changing /home/ubuntu/system/airflow/logs/dag_id=db_snapshot/run_id=scheduled__2023-12-21T00:00:00+00:00/task_id=run permission to 509
[[34m2023-12-23T16:41:03.383+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:41:04.479+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:41:05.471+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/cleanup.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
Changing /home/ubuntu/system/airflow/logs/dag_id=cleanup/run_id=scheduled__2023-12-21T00:00:00+00:00/task_id=run permission to 509
[[34m2023-12-23T16:41:07.672+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:41:08.677+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2023-12-23T16:41:08.678+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2023-12-23T16:41:08.686+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=db_snapshot, task_id=run, run_id=scheduled__2023-12-21T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:41:03.443674+00:00, run_end_date=2023-12-23 16:41:03.583165+00:00, run_duration=0.139491, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=12, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:41:00.115633+00:00, queued_by_job_id=9, pid=37835[0m
[[34m2023-12-23T16:41:08.687+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=cleanup, task_id=run, run_id=scheduled__2023-12-21T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:41:07.728960+00:00, run_end_date=2023-12-23 16:41:07.859815+00:00, run_duration=0.130855, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:41:00.115633+00:00, queued_by_job_id=9, pid=37882[0m
[[34m2023-12-23T16:41:08.713+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for db_snapshot to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:41:08.716+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for cleanup to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:41:08.747+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 2 tasks up for execution:
	<TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:41:08.747+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG db_snapshot has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:41:08.748+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG cleanup has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:41:08.748+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>
	<TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:41:08.749+0000[0m] {[34mtaskinstance.py:[0m2261} WARNING[0m - cannot record scheduled_duration for task run because previous state change time has not been saved[0m
[[34m2023-12-23T16:41:08.749+0000[0m] {[34mtaskinstance.py:[0m2261} WARNING[0m - cannot record scheduled_duration for task run because previous state change time has not been saved[0m
[[34m2023-12-23T16:41:08.749+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:41:08.750+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:41:08.750+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:41:08.750+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:41:08.751+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:41:09.720+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/db_snapshot.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
Changing /home/ubuntu/system/airflow/logs/dag_id=db_snapshot/run_id=scheduled__2023-12-22T00:00:00+00:00/task_id=run permission to 509
[[34m2023-12-23T16:41:11.917+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:41:12.923+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:41:13.932+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/cleanup.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
Changing /home/ubuntu/system/airflow/logs/dag_id=cleanup/run_id=scheduled__2023-12-22T00:00:00+00:00/task_id=run permission to 509
[[34m2023-12-23T16:41:16.229+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:41:17.250+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2023-12-23T16:41:17.250+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2023-12-23T16:41:17.254+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=db_snapshot, task_id=run, run_id=scheduled__2023-12-22T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:41:11.974283+00:00, run_end_date=2023-12-23 16:41:12.108675+00:00, run_duration=0.134392, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:41:08.748710+00:00, queued_by_job_id=9, pid=37935[0m
[[34m2023-12-23T16:41:17.255+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=cleanup, task_id=run, run_id=scheduled__2023-12-22T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:41:16.291371+00:00, run_end_date=2023-12-23 16:41:16.425206+00:00, run_duration=0.133835, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:41:08.748710+00:00, queued_by_job_id=9, pid=37996[0m
[[34m2023-12-23T16:42:32.876+0000[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2023-12-23T16:42:32.879+0000[0m] {[34mscheduler_job_runner.py:[0m1642} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[2023-12-23T16:42:38.721+0000] {process_utils.py:262} INFO - Waiting up to 5 seconds for processes to exit...
[[34m2023-12-23T16:46:04.369+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:04.369+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG db_snapshot has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:46:04.369+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:04.370+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:46:04.371+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:46:04.372+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:46:06.282+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/db_snapshot.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
[[34m2023-12-23T16:46:08.609+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: db_snapshot.run scheduled__2023-12-21T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:46:09.730+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=2, map_index=-1)[0m
[[34m2023-12-23T16:46:09.734+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=db_snapshot, task_id=run, run_id=scheduled__2023-12-21T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:46:08.720642+00:00, run_end_date=2023-12-23 16:46:08.859349+00:00, run_duration=0.138707, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=17, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:46:04.370146+00:00, queued_by_job_id=9, pid=40028[0m
[[34m2023-12-23T16:46:09.770+0000[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun db_snapshot @ 2023-12-21 00:00:00+00:00: scheduled__2023-12-21T00:00:00+00:00, state:running, queued_at: 2023-12-23 16:41:00.080847+00:00. externally triggered: False> failed[0m
[[34m2023-12-23T16:46:09.771+0000[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=db_snapshot, execution_date=2023-12-21 00:00:00+00:00, run_id=scheduled__2023-12-21T00:00:00+00:00, run_start_date=2023-12-23 16:41:00.097309+00:00, run_end_date=2023-12-23 16:46:09.771246+00:00, run_duration=309.673937, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-12-21 00:00:00+00:00, data_interval_end=2023-12-22 00:00:00+00:00, dag_hash=1f067657cc42eb42c8f255271d5735ed[0m
[[34m2023-12-23T16:46:09.773+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for db_snapshot to 2023-12-22T00:00:00+00:00, run_after=2023-12-23T00:00:00+00:00[0m
[[34m2023-12-23T16:46:09.786+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:09.786+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG cleanup has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:46:09.786+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:09.787+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:46:09.787+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:46:09.789+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:46:10.789+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/cleanup.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
[[34m2023-12-23T16:46:13.111+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: cleanup.run scheduled__2023-12-21T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:46:14.160+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-21T00:00:00+00:00', try_number=2, map_index=-1)[0m
[[34m2023-12-23T16:46:14.164+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=cleanup, task_id=run, run_id=scheduled__2023-12-21T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:46:13.170774+00:00, run_end_date=2023-12-23 16:46:13.306242+00:00, run_duration=0.135468, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:46:09.786892+00:00, queued_by_job_id=9, pid=40072[0m
[[34m2023-12-23T16:46:14.183+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for db_snapshot to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:46:14.200+0000[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun cleanup @ 2023-12-21 00:00:00+00:00: scheduled__2023-12-21T00:00:00+00:00, state:running, queued_at: 2023-12-23 16:41:00.089024+00:00. externally triggered: False> failed[0m
[[34m2023-12-23T16:46:14.200+0000[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=cleanup, execution_date=2023-12-21 00:00:00+00:00, run_id=scheduled__2023-12-21T00:00:00+00:00, run_start_date=2023-12-23 16:41:00.097495+00:00, run_end_date=2023-12-23 16:46:14.200760+00:00, run_duration=314.103265, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-12-21 00:00:00+00:00, data_interval_end=2023-12-22 00:00:00+00:00, dag_hash=bf455f52690c0bddd99f7b5874f3b546[0m
[[34m2023-12-23T16:46:14.203+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for cleanup to 2023-12-22T00:00:00+00:00, run_after=2023-12-23T00:00:00+00:00[0m
[[34m2023-12-23T16:46:14.211+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:14.211+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG db_snapshot has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:46:14.211+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:14.212+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:46:14.212+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:46:14.213+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'db_snapshot', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/db_snapshot.py'][0m
[[34m2023-12-23T16:46:15.205+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/db_snapshot.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
[[34m2023-12-23T16:46:17.534+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: db_snapshot.run scheduled__2023-12-22T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:46:18.647+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='db_snapshot', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=2, map_index=-1)[0m
[[34m2023-12-23T16:46:18.652+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=db_snapshot, task_id=run, run_id=scheduled__2023-12-22T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:46:17.599802+00:00, run_end_date=2023-12-23 16:46:17.744495+00:00, run_duration=0.144693, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:46:14.211876+00:00, queued_by_job_id=9, pid=40134[0m
[[34m2023-12-23T16:46:18.672+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for cleanup to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:46:18.683+0000[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun db_snapshot @ 2023-12-22 00:00:00+00:00: scheduled__2023-12-22T00:00:00+00:00, state:running, queued_at: 2023-12-23 16:41:08.711269+00:00. externally triggered: False> failed[0m
[[34m2023-12-23T16:46:18.683+0000[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=db_snapshot, execution_date=2023-12-22 00:00:00+00:00, run_id=scheduled__2023-12-22T00:00:00+00:00, run_start_date=2023-12-23 16:41:08.721498+00:00, run_end_date=2023-12-23 16:46:18.683800+00:00, run_duration=309.962302, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-12-22 00:00:00+00:00, data_interval_end=2023-12-23 00:00:00+00:00, dag_hash=1f067657cc42eb42c8f255271d5735ed[0m
[[34m2023-12-23T16:46:18.686+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for db_snapshot to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:46:18.701+0000[0m] {[34mscheduler_job_runner.py:[0m424} INFO[0m - 1 tasks up for execution:
	<TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:18.701+0000[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - DAG cleanup has 0/16 running and queued tasks[0m
[[34m2023-12-23T16:46:18.701+0000[0m] {[34mscheduler_job_runner.py:[0m603} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [scheduled]>[0m
[[34m2023-12-23T16:46:18.703+0000[0m] {[34mscheduler_job_runner.py:[0m646} INFO[0m - Sending TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-12-23T16:46:18.703+0000[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:46:18.704+0000[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'cleanup', 'run', 'scheduled__2023-12-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cleanup.py'][0m
[[34m2023-12-23T16:46:19.725+0000[0m] {[34mdagbag.py:[0m538} INFO[0m - Filling up the DagBag from /home/ubuntu/system/***/dags/cleanup.py[0m
/home/ubuntu/system/airflow/dags/../../HUST
[[34m2023-12-23T16:46:22.005+0000[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: cleanup.run scheduled__2023-12-22T00:00:00+00:00 [queued]> on host ip-172-31-35-148.ap-south-1.compute.internal[0m
[[34m2023-12-23T16:46:23.084+0000[0m] {[34mscheduler_job_runner.py:[0m696} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='cleanup', task_id='run', run_id='scheduled__2023-12-22T00:00:00+00:00', try_number=2, map_index=-1)[0m
[[34m2023-12-23T16:46:23.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=cleanup, task_id=run, run_id=scheduled__2023-12-22T00:00:00+00:00, map_index=-1, run_start_date=2023-12-23 16:46:22.065776+00:00, run_end_date=2023-12-23 16:46:22.207700+00:00, run_duration=0.141924, state=failed, executor_state=success, try_number=2, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2023-12-23 16:46:18.702079+00:00, queued_by_job_id=9, pid=40187[0m
[[34m2023-12-23T16:46:23.113+0000[0m] {[34mdagrun.py:[0m711} ERROR[0m - Marking run <DagRun cleanup @ 2023-12-22 00:00:00+00:00: scheduled__2023-12-22T00:00:00+00:00, state:running, queued_at: 2023-12-23 16:41:08.714240+00:00. externally triggered: False> failed[0m
[[34m2023-12-23T16:46:23.114+0000[0m] {[34mdagrun.py:[0m783} INFO[0m - DagRun Finished: dag_id=cleanup, execution_date=2023-12-22 00:00:00+00:00, run_id=scheduled__2023-12-22T00:00:00+00:00, run_start_date=2023-12-23 16:41:08.721608+00:00, run_end_date=2023-12-23 16:46:23.114446+00:00, run_duration=314.392838, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-12-22 00:00:00+00:00, data_interval_end=2023-12-23 00:00:00+00:00, dag_hash=bf455f52690c0bddd99f7b5874f3b546[0m
[[34m2023-12-23T16:46:23.116+0000[0m] {[34mdag.py:[0m3820} INFO[0m - Setting next_dagrun for cleanup to 2023-12-23T00:00:00+00:00, run_after=2023-12-24T00:00:00+00:00[0m
[[34m2023-12-23T16:47:32.909+0000[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2023-12-23T16:52:32.939+0000[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2023-12-23T16:57:32.967+0000[0m] {[34mscheduler_job_runner.py:[0m1619} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
